%Remember to use the following steps for compiling bibtex file in LaTeX file:
%1. PDFLaTeX
%2. BibTeX
%3. PDFLaTeX
%4. PDFLaTeX

@ieeetranbstctl{IEEEexample:BSTcontrol,
  ctluse_forced_etal       = {yes},
  ctlmax_names_forced_etal = {4},
  ctlnames_show_etal       = {3}
}

@article{xu2024chattf,
  author   = {Xu, Jun and Zhang, Hao and Zhang, Haijing and Lu, Jiawei and Xiao, Gang},
  journal  = {IEEE Access},
  title    = {ChatTf: A Knowledge Graph-Enhanced Intelligent Q\&A System for Mitigating Factuality Hallucinations in Traditional Folklore},
  year     = {2024},
  volume   = {12},
  pages    = {162638-162650},
  keywords = {Ontologies;Knowledge graphs;Cultural differences;Large language models;Knowledge engineering;Training;Cognition;Accuracy;Semantics;Reliability;Knowledge graph;large language model;question answering;retrieval-augmented generation;traditional folklore},
  doi      = {10.1109/ACCESS.2024.3485877}
}

@inproceedings{iga2024assessllm,
  author    = {Iga, Vasile Ionut Remus
               and Silaghi, Gheorghe Cosmin},
  editor    = {Besold, Tarek R.
               and d'Avila Garcez, Artur
               and Jimenez-Ruiz, Ernesto
               and Confalonieri, Roberto
               and Madhyastha, Pranava
               and Wagner, Benedikt},
  title     = {Assessing LLMs Suitability for Knowledge Graph Completion},
  booktitle = {Neural-Symbolic Learning and Reasoning},
  year      = {2024},
  publisher = {Springer Nature Switzerland},
  address   = {Cham},
  pages     = {277--290},
  abstract  = {Recent work has shown the capability of Large Language Models (LLMs) to solve tasks related to Knowledge Graphs, such as Knowledge Graph Completion, even in Zero- or Few-Shot paradigms. However, they are known to hallucinate answers, or output results in a non-deterministic manner, thus leading to wrongly reasoned responses, even if they satisfy the user's demands. To highlight opportunities and challenges in knowledge graphs-related tasks, we experiment with three distinguished LLMs, namely Mixtral-8x7b-Instruct-v0.1, GPT-3.5-Turbo-0125 and GPT-4o, on Knowledge Graph Completion for static knowledge graphs, using prompts constructed following the TELeR taxonomy, in Zero- and One-Shot contexts, on a Task-Oriented Dialogue system use case. When evaluated using both strict and flexible metrics measurement manners, our results show that LLMs could be fit for such a task if prompts encapsulate sufficient information and relevant examples.},
  isbn      = {978-3-031-71170-1}
}

@misc{santu2023telergeneraltaxonomyllm,
  title         = {TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks},
  author        = {Shubhra Kanti Karmaker Santu and Dongji Feng},
  year          = {2023},
  eprint        = {2305.11430},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2305.11430}
}

@article{meng2024domainontologydriven,
  author    = {Meng, Zhixin and Zhan, Shaoxiong and Xu, Ruiqing and Mayer, Wolfgang and Zhu, Ye and Zhang, Hong-Yu and He, Chuan and He, Keqing and Cheng, Debo and Feng, Zaiwen},
  title     = {Domain Ontology-Driven Knowledge Graph Generation from Text},
  year      = {2024},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3708478},
  doi       = {10.1145/3708478},
  abstract  = {A knowledge graph serves as a unified and standardized representation for extracting and representing textual information. In the field of knowledge extraction and representation research, named entity recognition and relation extraction provide effective solutions for knowledge graph generation tasks. However, it is a challenge that lies in extracting domain-specific knowledge from the rich and general textual corpora and generating corresponding domain knowledge graphs to support domain-specific reasoning, question-answering, and decision-making tasks. The hierarchical domain knowledge representation model (i.e. domain ontology) provides a solution for this problem. Therefore, we propose an end-to-end approach based on domain ontology embedding and pre-trained language models for domain knowledge graph generation from text, which incorporates domain node recognition and domain relation extraction phases. We evaluated our domain ontology-driven model on the Wikidata-TekGen dataset and the DBpedia-WebNLG dataset, and the results indicate that our approach based on the pre-trained language models with fewer parameters compared with the baseline models has significantly contributed to the domain knowledge graph generation without prompts.},
  note      = {Just Accepted},
  journal   = {ACM Trans. Probab. Mach. Learn.},
  month     = dec,
  keywords  = {Domain Knowledge Graph, Domain Ontology, Ontology Embedding, Domain Node Recognition, Domain Relation Extraction}
}

@inbook{xilong2025leveraginglargelanguagemodels,
  author    = {Xilong, Hou and Junhan, Zang and Xiaoguang, Wang},
  title     = {Leveraging Large Language Models for Classification of Cultural Heritage Domain Terms: A Case Study on CIDOC CRM},
  year      = {2025},
  isbn      = {9798400710933},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3677389.3702562},
  abstract  = {Large language models (LLMs) have recently revolutionized human language understanding and generation. Ontology is considered one of the primary cornerstones for representing knowledge in a more meaningful way on the semantic web. It's significant to explore whether LLMs know and understand such ontological knowledge. In this paper, we report an experiment to investigate the performance of LLMs in the task of classifying cultural heritage domain terms to upper-level ontology. We first probed the understanding and memorization of CIDOC CRM ontological knowledge by LLMs. Then, we further leverage LLMs to classify domain terms into the structure of CRM, and compare the match type with experts. Our initial findings indicate that LLMs demonstrate a certain level of awareness and comprehension of CIDOC CRM ontological knowledge. LLMs have shown potential as valuable assistants in enhancing ontology engineering and knowledge-intensive tasks.},
  booktitle = {Proceedings of the 24th ACM/IEEE Joint Conference on Digital Libraries},
  articleno = {59},
  numpages  = {5}
}

@inproceedings{siwi2024transformingindonesian,
  author    = {Siwi, Satria and Wiharja, Kemas and Hafizh, Raihan},
  booktitle = {2024 12th International Conference on Information and Communication Technology (ICoICT)},
  title     = {Transforming Indonesian Geography Education Books Into Knowledge Graphs Using ChatGPT LLMs},
  year      = {2024},
  volume    = {},
  number    = {},
  pages     = {50-56},
  abstract  = {This study demonstrates the construction of knowledge graphs from Indonesian geography education books using ChatGPT Large Language Models (LLMs) and Neo4j for visualization. The primary objective is to convert unstructured PDF text into structured, interactive knowledge representations to enhance learning experiences. The methodology involves extracting entities, relationships, and triples from the text, and organizing them into coherent knowledge graphs. Evaluations on four individual datasets and a combined dataset used Mean Reciprocal Rank (MRR) and HITS@10 metrics to assess performance. The results showed strong performance, with MRR values between 0.7087 and 0.8592 and HITS@10 values between 0.9274 and 1.0. The combined dataset achieved an MRR of 0.7695 and HITS@10 of 0.9570. These findings underscore the effectiveness of ChatGPT LLMs in converting unstructured text into dynamic, interactive knowledge representations, thereby enhancing the accessibility and utility of educational content. Confidence in using ChatGPT is supported by its high accuracy in data extraction, with minimal inappropriate references generated, which were easily manageable. ChatGPT was chosen over other AI tools due to its superior text generation and entity recognition capabilities. Future work will focus on optimizing the extraction processes, expanding the dataset scope, and further validating and improving the approach to ensure broader applicability and effectiveness in educational settings.},
  keywords  = {Geography;Measurement;Large language models;Education;Knowledge graphs;Transforms;Chatbots;Portable document format;Information and communication technology;Data mining;Knowledge Graphs;ChatGPT;Large Language Models (LLMs);Mean Reciprocal Rank (MRR);HITS@10;NLP},
  doi       = {10.1109/ICoICT61617.2024.10698487},
  issn      = {},
  month     = {Aug}
}


@inproceedings{doerr2005thecidoc,
  author    = {Doerr, Martin},
  title     = {{The CIDOC CRM, an Ontological Approach to Schema Heterogeneity}},
  booktitle = {Semantic Interoperability and Integration},
  pages     = {1--5},
  series    = {Dagstuhl Seminar Proceedings (DagSemProc)},
  issn      = {1862-4405},
  year      = {2005},
  volume    = {4391},
  editor    = {Y. Kalfoglou and M. Schorlemmer and A. Sheth and S. Staab and M. Uschold},
  publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  address   = {Dagstuhl, Germany},
  url       = {https://drops.dagstuhl.de/entities/document/10.4230/DagSemProc.04391.22},
  urn       = {urn:nbn:de:0030-drops-355},
  doi       = {10.4230/DagSemProc.04391.22},
  annote    = {Keywords: formal ontologies , knowledge engineering , semantic interoperability , core ontology , information integration , heterogeneous information museums}
}

@misc{zhu2024llmsknowledgegraphconstruction,
  title         = {LLMs for Knowledge Graph Construction and Reasoning: Recent Capabilities and Future Opportunities},
  author        = {Yuqi Zhu and Xiaohan Wang and Jing Chen and Shuofei Qiao and Yixin Ou and Yunzhi Yao and Shumin Deng and Huajun Chen and Ningyu Zhang},
  year          = {2024},
  eprint        = {2305.13168},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2305.13168}
}

@inproceedings{cauter2024ontology,
  title     = {Ontology-guided Knowledge Graph Construction from Maintenance Short Texts},
  author    = {van Cauter, Zeno  and
               Yakovets, Nikolay},
  editor    = {Biswas, Russa  and
               Kaffee, Lucie-Aim{\'e}e  and
               Agarwal, Oshin  and
               Minervini, Pasquale  and
               Singh, Sameer  and
               de Melo, Gerard},
  booktitle = {Proceedings of the 1st Workshop on Knowledge Graphs and Large Language Models (KaLLM 2024)},
  month     = aug,
  year      = {2024},
  address   = {Bangkok, Thailand},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2024.kallm-1.8/},
  doi       = {10.18653/v1/2024.kallm-1.8},
  pages     = {75--84},
  abstract  = {Large-scale knowledge graph construction remains infeasible since it requires significant human-expert involvement. Further complications arise when building graphs from domain-specific data due to their unique vocabularies and associated contexts. In this work, we demonstrate the ability of open-source large language models (LLMs), such as Llama-2 and Llama-3, to extract facts from domain-specific Maintenance Short Texts (MSTs). We employ an approach which combines ontology-guided triplet extraction and in-context learning. By using only 20 semantically similar examples with the Llama-3-70B-Instruct model, we achieve performance comparable to previous methods that relied on fine-tuning techniques like SpERT and REBEL. This indicates that domain-specific fact extraction can be accomplished through inference alone, requiring minimal labeled data. This opens up possibilities for effective and efficient semi-automated knowledge graph construction for domain-specific data.}
}

@misc{feng2025ontologyragbetterfasterbiomedical,
  title         = {OntologyRAG: Better and Faster Biomedical Code Mapping with Retrieval-Augmented Generation (RAG) Leveraging Ontology Knowledge Graphs and Large Language Models},
  author        = {Hui Feng and Yuntzu Yin and Emiliano Reynares and Jay Nanavati},
  year          = {2025},
  eprint        = {2502.18992},
  archiveprefix = {arXiv},
  primaryclass  = {cs.IR},
  url           = {https://arxiv.org/abs/2502.18992}
}

@inproceedings{usmanovausbeck2024structuring,
  title     = {Structuring Sustainability Reports for Environmental Standards with {LLM}s guided by Ontology},
  author    = {Usmanova, Aida  and
               Usbeck, Ricardo},
  editor    = {Stammbach, Dominik  and
               Ni, Jingwei  and
               Schimanski, Tobias  and
               Dutia, Kalyan  and
               Singh, Alok  and
               Bingler, Julia  and
               Christiaen, Christophe  and
               Kushwaha, Neetu  and
               Muccione, Veruska  and
               A. Vaghefi, Saeid  and
               Leippold, Markus},
  booktitle = {Proceedings of the 1st Workshop on Natural Language Processing Meets Climate Change (ClimateNLP 2024)},
  month     = aug,
  year      = {2024},
  address   = {Bangkok, Thailand},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2024.climatenlp-1.13/},
  doi       = {10.18653/v1/2024.climatenlp-1.13},
  pages     = {168--177},
  abstract  = {Following the introduction of the European Sustainability Reporting Standard (ESRS), companies will have to adapt to a new policy and provide mandatory sustainability reports. However, implementing such reports entails a challenge, such as the comprehension of a large number of textual information from various sources. This task can be accelerated by employing Large Language Models (LLMs) and ontologies to effectively model the domain knowledge. In this study, we extended an existing ontology to model ESRS Topical Standard for disclosure. The developed ontology would enable automated reasoning over the data and assist in constructing Knowledge Graphs (KGs). Moreover, the proposed ontology extension would also help to identify gaps in companies' sustainability reports with regard to the ESRS requirements.Additionally, we extracted knowledge from corporate sustainability reports via LLMs guided with a proposed ontology and developed their KG representation.}
}

@inproceedings{chen2023autokgefficient,
  author    = {Chen, Bohan and Bertozzi, Andrea L.},
  booktitle = {2023 IEEE International Conference on Big Data (BigData)},
  title     = {AutoKG: Efficient Automated Knowledge Graph Generation for Language Models},
  year      = {2023},
  volume    = {},
  number    = {},
  pages     = {3117-3126},
  abstract  = {Traditional methods of linking large language models (LLMs) to knowledge bases via the semantic similarity search often fall short of capturing complex relational dynamics. To address these limitations, we introduce AutoKG, a lightweight and efficient approach for automated knowledge graph (KG) construction. For a given knowledge base consisting of text blocks, AutoKG first extracts keywords using a LLM and then evaluates the relationship weight between each pair of keywords using graph Laplace learning. We employ a hybrid search scheme combining vector similarity and graph-based associations to enrich LLM responses. Preliminary experiments demonstrate that AutoKG offers a more comprehensive and interconnected knowledge retrieval mechanism compared to the semantic similarity search, thereby enhancing the capabilities of LLMs in generating more insightful and relevant outputs.},
  keywords  = {Training;Semantics;Knowledge based systems;Data visualization;Knowledge graphs;Computer architecture;Big Data;Language model;Knowledge Graph;Graph Learning;Retrieval-augmented Generation},
  doi       = {10.1109/BigData59044.2023.10386454},
  issn      = {},
  month     = {Dec}
}

@inproceedings{mihindukulasooriya2023text2kgbench,
  author    = {Mihindukulasooriya, Nandana
               and Tiwari, Sanju
               and Enguix, Carlos F.
               and Lata, Kusum},
  editor    = {Payne, Terry R.
               and Presutti, Valentina
               and Qi, Guilin
               and Poveda-Villal{\'o}n, Mar{\'i}a
               and Stoilos, Giorgos
               and Hollink, Laura
               and Kaoudi, Zoi
               and Cheng, Gong
               and Li, Juanzi},
  title     = {Text2KGBench: A Benchmark for Ontology-Driven Knowledge Graph Generation from Text},
  booktitle = {The Semantic Web -- ISWC 2023},
  year      = {2023},
  publisher = {Springer Nature Switzerland},
  address   = {Cham},
  pages     = {247--265},
  abstract  = {The recent advances in large language models (LLM) and foundation models with emergent capabilities have been shown to improve the performance of many NLP tasks. LLMs and Knowledge Graphs (KG) can complement each other such that LLMs can be used for KG construction or completion while existing KGs can be used for different tasks such as making LLM outputs explainable or fact-checking in Neuro-Symbolic manner. In this paper, we present Text2KGBench, a benchmark to evaluate the capabilities of language models to generate KGs from natural language text guided by an ontology. Given an input ontology and a set of sentences, the task is to extract facts from the text while complying with the given ontology (concepts, relations, domain/range constraints) and being faithful to the input sentences. We provide two datasets (i) Wikidata-TekGen with 10 ontologies and 13,474 sentences and (ii) DBpedia-WebNLG with 19 ontologies and 4,860 sentences. We define seven evaluation metrics to measure fact extraction performance, ontology conformance, and hallucinations by LLMs. Furthermore, we provide results for two baseline models, Vicuna-13B and Alpaca-LoRA-13B using automatic prompt generation from test cases. The baseline results show that there is room for improvement using both Semantic Web and Natural Language Processing techniques.},
  isbn      = {978-3-031-47243-5}
}

@inproceedings{carriero2025humanevaluationofprocedural,
  author    = {Carriero, Valentina Anita
               and Azzini, Antonia
               and Baroni, Ilaria
               and Scrocca, Mario
               and Celino, Irene},
  editor    = {Alam, Mehwish
               and Rospocher, Marco
               and van Erp, Marieke
               and Hollink, Laura
               and Gesese, Genet Asefa},
  title     = {Human Evaluation of Procedural Knowledge Graph Extraction from Text with Large Language Models},
  booktitle = {Knowledge Engineering and Knowledge Management},
  year      = {2025},
  publisher = {Springer Nature Switzerland},
  address   = {Cham},
  pages     = {434--452},
  abstract  = {Procedural Knowledge is the know-how expressed in the form of sequences of steps needed to perform some tasks. Procedures are usually described by means of natural language texts, such as recipes or maintenance manuals, possibly spread across different documents and systems, and their interpretation and subsequent execution is often left to the reader. Representing such procedures in a Knowledge Graph (KG) can be the basis to build digital tools to support those users who need to apply or execute them.},
  isbn      = {978-3-031-77792-9}
}

@inproceedings{ghanem2025enhancingknowledgegraphs,
  author    = {Ghanem, Hussam
               and Cruz, Christophe},
  editor    = {Tiwari, Sanju
               and Villaz{\'o}n-Terrazas, Boris
               and Ortiz-Rodr{\'i}guez, Fernando
               and Sahri, Soror},
  title     = {Enhancing Knowledge Graph Construction: Evaluating with Emphasis on Hallucination, Omission, and Graph Similarity Metrics},
  booktitle = {Knowledge Graphs and Semantic Web},
  year      = {2025},
  publisher = {Springer Nature Switzerland},
  address   = {Cham},
  pages     = {32--46},
  abstract  = {Recent advancements in large language models have demonstrated significant potential in the automated construction of knowledge graphs from unstructured text. This paper builds upon our previous work [16], which evaluated various models using metrics like precision, recall, F1 score, triple matching, and graph matching, and introduces a refined approach to address the critical issues of hallucination and omission. We propose an enhanced evaluation framework incorporating BERTScore for graph similarity, setting a practical threshold of 95{\%} for graph matching. Our experiments focus on the Mistral model, comparing its original and fine-tuned versions in zero-shot and few-shot settings. We further extend our experiments using examples from the KELM-sub training dataset, illustrating that the fine-tuned model significantly improves knowledge graph construction accuracy while reducing the exact hallucination and omission. However, our findings also reveal that the fine-tuned models perform worse in generalization tasks on the KELM-sub dataset. This study underscores the importance of comprehensive evaluation metrics in advancing the state-of-the-art in knowledge graph construction from textual data.},
  isbn      = {978-3-031-81221-7}
}

@inbook{bruseker2017culturalheritagedatamanagement,
  author    = {Bruseker, George
               and Carboni, Nicola
               and Guillem, Ana{\"i}s},
  editor    = {Vincent, Matthew L.
               and L{\'o}pez-Menchero Bendicho, V{\'i}ctor Manuel
               and Ioannides, Marinos
               and Levy, Thomas E.},
  title     = {Cultural Heritage Data Management: The Role of Formal Ontology and CIDOC CRM},
  booktitle = {Heritage and Archaeology in the Digital Age: Acquisition, Curation, and Dissemination of Spatial Cultural Heritage Data},
  year      = {2017},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {93--131},
  abstract  = {Building models for integrating the diverse data generated in Cultural Heritage disciplines is a long-term challenge both for securing presently generated knowledge and for making it progressively more widely accessible and interoperable into the future. This chapter reviews the multiple approaches undertaken to address this problem, finally proposing CIDOC CRM as the most robust solution for information integration in CH. The chapter begins by outlining the data challenge specific to the field and the main approaches that can be taken in facing it. Within this frame, it distinguishes knowledge engineering and formal ontology from other information modelling techniques as the necessary approach for tackling the broader data integration problem. It then outlines the basic principles of CIDOC CRM, the ISO standard formal ontology for CH. From there, an overview is given of some of the work that has been done both theoretically and in practice over the past five years in developing and implementing CRM as a practical data integration strategy in CH, particularly looking at model extensions to handle knowledge provenance across various disciplines and typical documentation and reasoning activities, as well as at successful implementation projects. Lastly, it summarizes the present potentials and challenges for using CIDOC CRM for solving the CH data management and integration puzzle. The intended audience of this chapter are specialists from all backgrounds within the broader domain of CH with an interest in data integration and CIDOC CRM.},
  isbn      = {978-3-319-65370-9},
  doi       = {10.1007/978-3-319-65370-9_6},
  url       = {https://doi.org/10.1007/978-3-319-65370-9\_6}
}

@inproceedings{lairgi2025itext2kgincremental,
  author    = {Lairgi, Yassir
               and Moncla, Ludovic
               and Cazabet, R{\'e}my
               and Benabdeslem, Khalid
               and Cl{\'e}au, Pierre},
  editor    = {Barhamgi, Mahmoud
               and Wang, Hua
               and Wang, Xin},
  title     = {iText2KG: Incremental Knowledge Graphs Construction Using Large Language Models},
  booktitle = {Web Information Systems Engineering -- WISE 2024},
  year      = {2025},
  publisher = {Springer Nature Singapore},
  address   = {Singapore},
  pages     = {214--229},
  abstract  = {Most available data is unstructured, making it challenging to access valuable information. Automatically building Knowledge Graphs (KGs) is crucial for structuring data and making it accessible, allowing users to search for information effectively. KGs also facilitate insights, inference, and reasoning. Traditional NLP methods, such as named entity recognition and relation extraction, are key in information retrieval but face limitations, including predefined entity types and the need for supervised learning. Current research leverages large language models' capabilities, such as zero- or few-shot learning. However, unresolved and semantically duplicated entities and relations still pose challenges, leading to inconsistent graphs and requiring extensive post-processing. Additionally, most approaches are topic-dependent. In this paper, we propose iText2KG (The code and the dataset are available at https://github.com/AuvaLab/itext2kg), a method for incremental, topic-independent KG construction without post-processing. This plug-and-play, zero-shot method is applicable across a wide range of KG construction scenarios and comprises four modules: Documents Distiller, Incremental Entities Extractor, Incremental Relations Extractor, and Graph Integrator. Our method demonstrates superior performance compared to baseline methods across three scenarios: converting scientific papers to graphs, websites to graphs, and CVs to graphs.},
  isbn      = {978-981-96-0573-6}
}

@article{caufield2024structuredpromptinterrogation,
  author   = {Caufield, J Harry and Hegde, Harshad and Emonet, Vincent and Harris, Nomi L and Joachimiak, Marcin P and Matentzoglu, Nicolas and Kim, HyeongSik and Moxon, Sierra and Reese, Justin T and Haendel, Melissa A and Robinson, Peter N and Mungall, Christopher J},
  title    = {Structured Prompt Interrogation and Recursive Extraction of Semantics (SPIRES): a method for populating knowledge bases using zero-shot learning},
  journal  = {Bioinformatics},
  volume   = {40},
  number   = {3},
  pages    = {btae104},
  year     = {2024},
  month    = {02},
  abstract = {Creating knowledge bases and ontologies is a time consuming task that relies on manual curation. AI/NLP approaches can assist expert curators in populating these knowledge bases, but current approaches rely on extensive training data, and are not able to populate arbitrarily complex nested knowledge schemas.Here we present Structured Prompt Interrogation and Recursive Extraction of Semantics (SPIRES), a Knowledge Extraction approach that relies on the ability of Large Language Models (LLMs) to perform zero-shot learning and general-purpose query answering from flexible prompts and return information conforming to a specified schema. Given a detailed, user-defined knowledge schema and an input text, SPIRES recursively performs prompt interrogation against an LLM to obtain a set of responses matching the provided schema. SPIRES uses existing ontologies and vocabularies to provide identifiers for matched elements. We present examples of applying SPIRES in different domains, including extraction of food recipes, multi-species cellular signaling pathways, disease treatments, multi-step drug mechanisms, and chemical to disease relationships. Current SPIRES accuracy is comparable to the mid-range of existing Relation Extraction methods, but greatly surpasses an LLM’s native capability of grounding entities with unique identifiers. SPIRES has the advantage of easy customization, flexibility, and, crucially, the ability to perform new tasks in the absence of any new training data. This method supports a general strategy of leveraging the language interpreting capabilities of LLMs to assemble knowledge bases, assisting manual knowledge curation and acquisition while supporting validation with publicly-available databases and ontologies external to the LLM.SPIRES is available as part of the open source OntoGPT package: https://github.com/monarch-initiative/ontogpt.},
  issn     = {1367-4811},
  doi      = {10.1093/bioinformatics/btae104},
  url      = {https://doi.org/10.1093/bioinformatics/btae104},
  eprint   = {https://academic.oup.com/bioinformatics/article-pdf/40/3/btae104/56912793/btae104.pdf}
}

@article{hofer2024constructionofknowledge,
  author         = {Hofer, Marvin and Obraczka, Daniel and Saeedi, Alieh and Köpcke, Hanna and Rahm, Erhard},
  title          = {Construction of Knowledge Graphs: Current State and Challenges},
  journal        = {Information},
  volume         = {15},
  year           = {2024},
  number         = {8},
  article-number = {509},
  url            = {https://www.mdpi.com/2078-2489/15/8/509},
  issn           = {2078-2489},
  abstract       = {With Knowledge Graphs (KGs) at the center of numerous applications such as recommender systems and question-answering, the need for generalized pipelines to construct and continuously update such KGs is increasing. While the individual steps that are necessary to create KGs from unstructured sources (e.g., text) and structured data sources (e.g., databases) are mostly well researched for their one-shot execution, their adoption for incremental KG updates and the interplay of the individual steps have hardly been investigated in a systematic manner so far. In this work, we first discuss the main graph models for KGs and introduce the major requirements for future KG construction pipelines. Next, we provide an overview of the necessary steps to build high-quality KGs, including cross-cutting topics such as metadata management, ontology development, and quality assurance. We then evaluate the state of the art of KG construction with respect to the introduced requirements for specific popular KGs, as well as some recent tools and strategies for KG construction. Finally, we identify areas in need of further research and improvement.},
  doi            = {10.3390/info15080509}
}

@article{remadi2024topromptornottoprompt,
  title    = {To prompt or not to prompt: Navigating the use of Large Language Models for integrating and modeling heterogeneous data},
  journal  = {Data \& Knowledge Engineering},
  volume   = {152},
  pages    = {102313},
  year     = {2024},
  issn     = {0169-023X},
  doi      = {https://doi.org/10.1016/j.datak.2024.102313},
  url      = {https://www.sciencedirect.com/science/article/pii/S0169023X24000375},
  author   = {Adel Remadi and Karim {El Hage} and Yasmina Hobeika and Francesca Bugiotti},
  keywords = {Data engineering, Large language models, Conceptual schema modeling, Entity resolution, Data integration, Property graph models},
  abstract = {Manually integrating data of diverse formats and languages is vital to many artificial intelligence applications. However, the task itself remains challenging and time-consuming. This paper highlights the potential of Large Language Models (LLMs) to streamline data extraction and resolution processes. Our approach aims to address the ongoing challenge of integrating heterogeneous data sources, encouraging advancements in the field of data engineering. Applied on the specific use case of learning disorders in higher education, our research demonstrates LLMs’ capability to effectively extract data from unstructured sources. It is then further highlighted that LLMs can enhance data integration by providing the ability to resolve entities originating from multiple data sources. Crucially, the paper underscores the necessity of preliminary data modeling decisions to ensure the success of such technological applications. By merging human expertise with LLM-driven automation, this study advocates for the further exploration of semi-autonomous data engineering pipelines.}
}

@article{dutia2021heritageconnector,
  author   = {Dutia, Kalyan and Stack, John},
  title    = {Heritage connector: A machine learning framework for building linked open data from museum collections},
  journal  = {Applied AI Letters},
  volume   = {2},
  number   = {2},
  pages    = {e23},
  keywords = {information retrieval, knowledge graphs, museums, record linkage},
  doi      = {https://doi.org/10.1002/ail2.23},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1002/ail2.23},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/ail2.23},
  abstract = {Abstract As with almost all data, museum collection catalogues are largely unstructured, variable in consistency and overwhelmingly composed of thin records. The form of these catalogues means that the potential for new forms of research, access and scholarly enquiry that range across multiple collections and related datasets remains dormant. In the project Heritage Connector: Transforming text into data to extract meaning and make connections, we are applying a battery of digital techniques to connect similar, identical and related objects within and across collections and other publications. In this article, we describe a framework to create a Linked Open Data knowledge graph from digital museum catalogues, perform record linkage to Wikidata, and add new entities to this graph from textual catalogue record descriptions (information retrieval). We focus on the use of machine learning to create these links at scale with a small amount of labelled data, and models which are small enough to run inference on datasets the size of museum collections on a mid-range laptop or a small cloud virtual machine. Our method for record linkage against Wikidata achieves 85\%+ precision with the Science Museum Group (SMG) collection, and our method for information retrieval is shown to improve NER performance compared with pretrained models on the SMG collection with no labelled training data. We publish open-source software providing tools to perform these tasks.},
  year     = {2021}
}

@article{ibrahim2024asurveyonaugmentingknowledgegraphs,
  author   = {Ibrahim, Nourhan
              and Aboulela, Samar
              and Ibrahim, Ahmed
              and Kashef, Rasha},
  title    = {A survey on augmenting knowledge graphs (KGs) with large language models (LLMs): models, evaluation metrics, benchmarks, and challenges},
  journal  = {Discover Artificial Intelligence},
  year     = {2024},
  month    = {Nov},
  day      = {04},
  volume   = {4},
  number   = {1},
  pages    = {76},
  abstract = {Integrating Large Language Models (LLMs) with Knowledge Graphs (KGs) enhances the interpretability and performance of AI systems. This research comprehensively analyzes this integration, classifying approaches into three fundamental paradigms: KG-augmented LLMs, LLM-augmented KGs, and synergized frameworks. The evaluation examines each paradigm's methodology, strengths, drawbacks, and practical applications in real-life scenarios. The findings highlight the substantial impact of these integrations in fundamentally improving real-time data analysis, efficient decision-making, and promoting innovation across various domains. In this paper, we also describe essential evaluation metrics and benchmarks for assessing the performance of these integrations, addressing challenges like scalability and computational overhead, and providing potential solutions. This comprehensive analysis underscores the profound impact of these integrations on improving real-time data analysis, enhancing decision-making efficiency, and fostering innovation across various domains.},
  issn     = {2731-0809},
  doi      = {10.1007/s44163-024-00175-8},
  url      = {https://doi.org/10.1007/s44163-024-00175-8}
}

@article{kalyan2021heritageconnector,
  author   = {Dutia, Kalyan and Stack, John},
  title    = {Heritage connector: A machine learning framework for building linked open data from museum collections},
  journal  = {Applied AI Letters},
  volume   = {2},
  number   = {2},
  pages    = {e23},
  keywords = {information retrieval, knowledge graphs, museums, record linkage},
  doi      = {https://doi.org/10.1002/ail2.23},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1002/ail2.23},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/ail2.23},
  abstract = {Abstract As with almost all data, museum collection catalogues are largely unstructured, variable in consistency and overwhelmingly composed of thin records. The form of these catalogues means that the potential for new forms of research, access and scholarly enquiry that range across multiple collections and related datasets remains dormant. In the project Heritage Connector: Transforming text into data to extract meaning and make connections, we are applying a battery of digital techniques to connect similar, identical and related objects within and across collections and other publications. In this article, we describe a framework to create a Linked Open Data knowledge graph from digital museum catalogues, perform record linkage to Wikidata, and add new entities to this graph from textual catalogue record descriptions (information retrieval). We focus on the use of machine learning to create these links at scale with a small amount of labelled data, and models which are small enough to run inference on datasets the size of museum collections on a mid-range laptop or a small cloud virtual machine. Our method for record linkage against Wikidata achieves 85\%+ precision with the Science Museum Group (SMG) collection, and our method for information retrieval is shown to improve NER performance compared with pretrained models on the SMG collection with no labelled training data. We publish open-source software providing tools to perform these tasks.},
  year     = {2021}
}

@inproceedings{pedro2013connectingthesmithsonian,
  author    = {Szekely, Pedro
               and Knoblock, Craig A.
               and Yang, Fengyu
               and Zhu, Xuming
               and Fink, Eleanor E.
               and Allen, Rachel
               and Goodlander, Georgina},
  editor    = {Cimiano, Philipp
               and Corcho, Oscar
               and Presutti, Valentina
               and Hollink, Laura
               and Rudolph, Sebastian},
  title     = {Connecting the Smithsonian American Art Museum to the Linked Data Cloud},
  booktitle = {The Semantic Web: Semantics and Big Data},
  year      = {2013},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {593--607},
  abstract  = {Museums around the world have built databases with metadata about millions of objects, their history, the people who created them, and the entities they represent. This data is stored in proprietary databases and is not readily available for use. Recently, museums embraced the Semantic Web as a means to make this data available to the world, but the experience so far shows that publishing museum data to the linked data cloud is difficult: the databases are large and complex, the information is richly structured and varies from museum to museum, and it is difficult to link the data to other datasets. This paper describes the process and lessons learned in publishing the data from the Smithsonian American Art Museum (SAAM). We highlight complexities of the database-to-RDF mapping process, discuss our experience linking the SAAM dataset to hub datasets such as DBpedia and the Getty Vocabularies, and present our experience in allowing SAAM personnel to review the information to verify that it meets the high standards of the Smithsonian. Using our tools, we helped SAAM publish high-quality linked data of their complete holdings (41,000 objects and 8,000 artists).},
  isbn      = {978-3-642-38288-8}
}

@article{alexiev2018museum,
  title     = {Museum linked open data: Ontologies, datasets, projects},
  author    = {Alexiev, Vladimir},
  journal   = {Digital Presentation and Preservation of Cultural and Scientific Heritage},
  number    = {VIII},
  pages     = {19--50},
  year      = {2018},
  publisher = {Институт по математика и информатика-Българска академия на науките}
}

@misc{qwen2025qwen25technicalreport,
  title         = {Qwen2.5 Technical Report},
  author        = {Qwen and : and An Yang and Baosong Yang and Beichen Zhang and Binyuan Hui and Bo Zheng and Bowen Yu and Chengyuan Li and Dayiheng Liu and Fei Huang and Haoran Wei and Huan Lin and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Yang and Jiaxi Yang and Jingren Zhou and Junyang Lin and Kai Dang and Keming Lu and Keqin Bao and Kexin Yang and Le Yu and Mei Li and Mingfeng Xue and Pei Zhang and Qin Zhu and Rui Men and Runji Lin and Tianhao Li and Tianyi Tang and Tingyu Xia and Xingzhang Ren and Xuancheng Ren and Yang Fan and Yang Su and Yichang Zhang and Yu Wan and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zihan Qiu},
  year          = {2025},
  eprint        = {2412.15115},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2412.15115}
}

@misc{grattafiori2024llama3herdmodels,
  title         = {The Llama 3 Herd of Models},
  author        = {Aaron Grattafiori and Abhimanyu Dubey and Abhinav Jauhri and Abhinav Pandey and Abhishek Kadian and Ahmad Al-Dahle and Aiesha Letman and Akhil Mathur and Alan Schelten and Alex Vaughan and Amy Yang and Angela Fan and Anirudh Goyal and Anthony Hartshorn and Aobo Yang and Archi Mitra and Archie Sravankumar and Artem Korenev and Arthur Hinsvark and Arun Rao and Aston Zhang and Aurelien Rodriguez and Austen Gregerson and Ava Spataru and Baptiste Roziere and Bethany Biron and Binh Tang and Bobbie Chern and Charlotte Caucheteux and Chaya Nayak and Chloe Bi and Chris Marra and Chris McConnell and Christian Keller and Christophe Touret and Chunyang Wu and Corinne Wong and Cristian Canton Ferrer and Cyrus Nikolaidis and Damien Allonsius and Daniel Song and Danielle Pintz and Danny Livshits and Danny Wyatt and David Esiobu and Dhruv Choudhary and Dhruv Mahajan and Diego Garcia-Olano and Diego Perino and Dieuwke Hupkes and Egor Lakomkin and Ehab AlBadawy and Elina Lobanova and Emily Dinan and Eric Michael Smith and Filip Radenovic and Francisco Guzmán and Frank Zhang and Gabriel Synnaeve and Gabrielle Lee and Georgia Lewis Anderson and Govind Thattai and Graeme Nail and Gregoire Mialon and Guan Pang and Guillem Cucurell and Hailey Nguyen and Hannah Korevaar and Hu Xu and Hugo Touvron and Iliyan Zarov and Imanol Arrieta Ibarra and Isabel Kloumann and Ishan Misra and Ivan Evtimov and Jack Zhang and Jade Copet and Jaewon Lee and Jan Geffert and Jana Vranes and Jason Park and Jay Mahadeokar and Jeet Shah and Jelmer van der Linde and Jennifer Billock and Jenny Hong and Jenya Lee and Jeremy Fu and Jianfeng Chi and Jianyu Huang and Jiawen Liu and Jie Wang and Jiecao Yu and Joanna Bitton and Joe Spisak and Jongsoo Park and Joseph Rocca and Joshua Johnstun and Joshua Saxe and Junteng Jia and Kalyan Vasuden Alwala and Karthik Prasad and Kartikeya Upasani and Kate Plawiak and Ke Li and Kenneth Heafield and Kevin Stone and Khalid El-Arini and Krithika Iyer and Kshitiz Malik and Kuenley Chiu and Kunal Bhalla and Kushal Lakhotia and Lauren Rantala-Yeary and Laurens van der Maaten and Lawrence Chen and Liang Tan and Liz Jenkins and Louis Martin and Lovish Madaan and Lubo Malo and Lukas Blecher and Lukas Landzaat and Luke de Oliveira and Madeline Muzzi and Mahesh Pasupuleti and Mannat Singh and Manohar Paluri and Marcin Kardas and Maria Tsimpoukelli and Mathew Oldham and Mathieu Rita and Maya Pavlova and Melanie Kambadur and Mike Lewis and Min Si and Mitesh Kumar Singh and Mona Hassan and Naman Goyal and Narjes Torabi and Nikolay Bashlykov and Nikolay Bogoychev and Niladri Chatterji and Ning Zhang and Olivier Duchenne and Onur Çelebi and Patrick Alrassy and Pengchuan Zhang and Pengwei Li and Petar Vasic and Peter Weng and Prajjwal Bhargava and Pratik Dubal and Praveen Krishnan and Punit Singh Koura and Puxin Xu and Qing He and Qingxiao Dong and Ragavan Srinivasan and Raj Ganapathy and Ramon Calderer and Ricardo Silveira Cabral and Robert Stojnic and Roberta Raileanu and Rohan Maheswari and Rohit Girdhar and Rohit Patel and Romain Sauvestre and Ronnie Polidoro and Roshan Sumbaly and Ross Taylor and Ruan Silva and Rui Hou and Rui Wang and Saghar Hosseini and Sahana Chennabasappa and Sanjay Singh and Sean Bell and Seohyun Sonia Kim and Sergey Edunov and Shaoliang Nie and Sharan Narang and Sharath Raparthy and Sheng Shen and Shengye Wan and Shruti Bhosale and Shun Zhang and Simon Vandenhende and Soumya Batra and Spencer Whitman and Sten Sootla and Stephane Collot and Suchin Gururangan and Sydney Borodinsky and Tamar Herman and Tara Fowler and Tarek Sheasha and Thomas Georgiou and Thomas Scialom and Tobias Speckbacher and Todor Mihaylov and Tong Xiao and Ujjwal Karn and Vedanuj Goswami and Vibhor Gupta and Vignesh Ramanathan and Viktor Kerkez and Vincent Gonguet and Virginie Do and Vish Vogeti and Vítor Albiero and Vladan Petrovic and Weiwei Chu and Wenhan Xiong and Wenyin Fu and Whitney Meers and Xavier Martinet and Xiaodong Wang and Xiaofang Wang and Xiaoqing Ellen Tan and Xide Xia and Xinfeng Xie and Xuchao Jia and Xuewei Wang and Yaelle Goldschlag and Yashesh Gaur and Yasmine Babaei and Yi Wen and Yiwen Song and Yuchen Zhang and Yue Li and Yuning Mao and Zacharie Delpierre Coudert and Zheng Yan and Zhengxing Chen and Zoe Papakipos and Aaditya Singh and Aayushi Srivastava and Abha Jain and Adam Kelsey and Adam Shajnfeld and Adithya Gangidi and Adolfo Victoria and Ahuva Goldstand and Ajay Menon and Ajay Sharma and Alex Boesenberg and Alexei Baevski and Allie Feinstein and Amanda Kallet and Amit Sangani and Amos Teo and Anam Yunus and Andrei Lupu and Andres Alvarado and Andrew Caples and Andrew Gu and Andrew Ho and Andrew Poulton and Andrew Ryan and Ankit Ramchandani and Annie Dong and Annie Franco and Anuj Goyal and Aparajita Saraf and Arkabandhu Chowdhury and Ashley Gabriel and Ashwin Bharambe and Assaf Eisenman and Azadeh Yazdan and Beau James and Ben Maurer and Benjamin Leonhardi and Bernie Huang and Beth Loyd and Beto De Paola and Bhargavi Paranjape and Bing Liu and Bo Wu and Boyu Ni and Braden Hancock and Bram Wasti and Brandon Spence and Brani Stojkovic and Brian Gamido and Britt Montalvo and Carl Parker and Carly Burton and Catalina Mejia and Ce Liu and Changhan Wang and Changkyu Kim and Chao Zhou and Chester Hu and Ching-Hsiang Chu and Chris Cai and Chris Tindal and Christoph Feichtenhofer and Cynthia Gao and Damon Civin and Dana Beaty and Daniel Kreymer and Daniel Li and David Adkins and David Xu and Davide Testuggine and Delia David and Devi Parikh and Diana Liskovich and Didem Foss and Dingkang Wang and Duc Le and Dustin Holland and Edward Dowling and Eissa Jamil and Elaine Montgomery and Eleonora Presani and Emily Hahn and Emily Wood and Eric-Tuan Le and Erik Brinkman and Esteban Arcaute and Evan Dunbar and Evan Smothers and Fei Sun and Felix Kreuk and Feng Tian and Filippos Kokkinos and Firat Ozgenel and Francesco Caggioni and Frank Kanayet and Frank Seide and Gabriela Medina Florez and Gabriella Schwarz and Gada Badeer and Georgia Swee and Gil Halpern and Grant Herman and Grigory Sizov and Guangyi and Zhang and Guna Lakshminarayanan and Hakan Inan and Hamid Shojanazeri and Han Zou and Hannah Wang and Hanwen Zha and Haroun Habeeb and Harrison Rudolph and Helen Suk and Henry Aspegren and Hunter Goldman and Hongyuan Zhan and Ibrahim Damlaj and Igor Molybog and Igor Tufanov and Ilias Leontiadis and Irina-Elena Veliche and Itai Gat and Jake Weissman and James Geboski and James Kohli and Janice Lam and Japhet Asher and Jean-Baptiste Gaya and Jeff Marcus and Jeff Tang and Jennifer Chan and Jenny Zhen and Jeremy Reizenstein and Jeremy Teboul and Jessica Zhong and Jian Jin and Jingyi Yang and Joe Cummings and Jon Carvill and Jon Shepard and Jonathan McPhie and Jonathan Torres and Josh Ginsburg and Junjie Wang and Kai Wu and Kam Hou U and Karan Saxena and Kartikay Khandelwal and Katayoun Zand and Kathy Matosich and Kaushik Veeraraghavan and Kelly Michelena and Keqian Li and Kiran Jagadeesh and Kun Huang and Kunal Chawla and Kyle Huang and Lailin Chen and Lakshya Garg and Lavender A and Leandro Silva and Lee Bell and Lei Zhang and Liangpeng Guo and Licheng Yu and Liron Moshkovich and Luca Wehrstedt and Madian Khabsa and Manav Avalani and Manish Bhatt and Martynas Mankus and Matan Hasson and Matthew Lennie and Matthias Reso and Maxim Groshev and Maxim Naumov and Maya Lathi and Meghan Keneally and Miao Liu and Michael L. Seltzer and Michal Valko and Michelle Restrepo and Mihir Patel and Mik Vyatskov and Mikayel Samvelyan and Mike Clark and Mike Macey and Mike Wang and Miquel Jubert Hermoso and Mo Metanat and Mohammad Rastegari and Munish Bansal and Nandhini Santhanam and Natascha Parks and Natasha White and Navyata Bawa and Nayan Singhal and Nick Egebo and Nicolas Usunier and Nikhil Mehta and Nikolay Pavlovich Laptev and Ning Dong and Norman Cheng and Oleg Chernoguz and Olivia Hart and Omkar Salpekar and Ozlem Kalinli and Parkin Kent and Parth Parekh and Paul Saab and Pavan Balaji and Pedro Rittner and Philip Bontrager and Pierre Roux and Piotr Dollar and Polina Zvyagina and Prashant Ratanchandani and Pritish Yuvraj and Qian Liang and Rachad Alao and Rachel Rodriguez and Rafi Ayub and Raghotham Murthy and Raghu Nayani and Rahul Mitra and Rangaprabhu Parthasarathy and Raymond Li and Rebekkah Hogan and Robin Battey and Rocky Wang and Russ Howes and Ruty Rinott and Sachin Mehta and Sachin Siby and Sai Jayesh Bondu and Samyak Datta and Sara Chugh and Sara Hunt and Sargun Dhillon and Sasha Sidorov and Satadru Pan and Saurabh Mahajan and Saurabh Verma and Seiji Yamamoto and Sharadh Ramaswamy and Shaun Lindsay and Shaun Lindsay and Sheng Feng and Shenghao Lin and Shengxin Cindy Zha and Shishir Patil and Shiva Shankar and Shuqiang Zhang and Shuqiang Zhang and Sinong Wang and Sneha Agarwal and Soji Sajuyigbe and Soumith Chintala and Stephanie Max and Stephen Chen and Steve Kehoe and Steve Satterfield and Sudarshan Govindaprasad and Sumit Gupta and Summer Deng and Sungmin Cho and Sunny Virk and Suraj Subramanian and Sy Choudhury and Sydney Goldman and Tal Remez and Tamar Glaser and Tamara Best and Thilo Koehler and Thomas Robinson and Tianhe Li and Tianjun Zhang and Tim Matthews and Timothy Chou and Tzook Shaked and Varun Vontimitta and Victoria Ajayi and Victoria Montanez and Vijai Mohan and Vinay Satish Kumar and Vishal Mangla and Vlad Ionescu and Vlad Poenaru and Vlad Tiberiu Mihailescu and Vladimir Ivanov and Wei Li and Wenchen Wang and Wenwen Jiang and Wes Bouaziz and Will Constable and Xiaocheng Tang and Xiaojian Wu and Xiaolan Wang and Xilun Wu and Xinbo Gao and Yaniv Kleinman and Yanjun Chen and Ye Hu and Ye Jia and Ye Qi and Yenda Li and Yilin Zhang and Ying Zhang and Yossi Adi and Youngjin Nam and Yu and Wang and Yu Zhao and Yuchen Hao and Yundi Qian and Yunlu Li and Yuzi He and Zach Rait and Zachary DeVito and Zef Rosnbrick and Zhaoduo Wen and Zhenyu Yang and Zhiwei Zhao and Zhiyu Ma},
  year          = {2024},
  eprint        = {2407.21783},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2407.21783}
}

@misc{deepseekai2024deepseekv3technicalreport,
  title         = {DeepSeek-V3 Technical Report},
  author        = {DeepSeek-AI},
  year          = {2024},
  eprint        = {2412.19437},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2412.19437}
}

@misc{deepseekai2025deepseekr1incentivizingreasoningcapability,
  title         = {DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning},
  author        = {DeepSeek-AI},
  year          = {2025},
  eprint        = {2501.12948},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2501.12948}
}
